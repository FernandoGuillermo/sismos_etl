# ğŸŒ SISMOS_ETL - Pipeline ETL con Airflow + PostgreSQL + Streamlit

Este proyecto implementa un pipeline de datos que **extrae informaciÃ³n de sismos desde la API del USGS**, la **transforma y la almacena en una base de datos PostgreSQL en Azure** utilizando Apache Airflow. AdemÃ¡s, se proporciona una visualizaciÃ³n interactiva mediante **Streamlit**.

---

## ğŸ“ Estructura del Proyecto

```
SISMOS_ETL/
â”œâ”€â”€ airflow/                  # Proyecto Airflow
â”‚   â”œâ”€â”€ dags/                # DAGs y funciones ETL
â”‚   â”‚   â”œâ”€â”€ earthquake_etl.py
â”‚   â”‚   â”œâ”€â”€ carga.py
â”‚   â”‚   â””â”€â”€ extracciÃ³n_transformacion.py
â”‚   â”œâ”€â”€ plugins/             # (vacÃ­o por ahora)
â”œâ”€â”€ streamlit_app/           # App de visualizaciÃ³n
â”‚   â””â”€â”€ visualizar_streamlit.py
â”œâ”€â”€ .env                     # âš ï¸ Variables de entorno (NO subir)
â”œâ”€â”€ .env.example             # Plantilla para .env
â”œâ”€â”€ .gitignore               # Ignora archivos innecesarios
â”œâ”€â”€ Dockerfile               # Imagen personalizada Airflow
â”œâ”€â”€ docker-compose.yml       # OrquestaciÃ³n de servicios
â”œâ”€â”€ requirements.txt         # Dependencias del entorno
â””â”€â”€ README.md
```

---

## ğŸš€ TecnologÃ­as utilizadas

- **Python 3.7**
- **Apache Airflow 2.5.1**
- **PostgreSQL (Azure)**
- **Streamlit**
- **Docker + Docker Compose**

---

## âš™ï¸ ConfiguraciÃ³n del entorno

### 1. Clonar el repositorio

```bash
git clone https://github.com/tu_usuario/sismos_etl.git
cd sismos_etl
```

### 2. Crear archivo `.env`

Copiar la plantilla y completarla con tus datos reales:

```bash
cp .env.example .env
```

### 3. Levantar los servicios con Docker

```bash
docker-compose up --build
```

AccedÃ© a Airflow en: [http://localhost:8080](http://localhost:8080)  
Usuario: `admin` | ContraseÃ±a: `admin`

---

## ğŸ’¾ Variables de entorno

El archivo `.env` contiene:

```env
# ConexiÃ³n a la base de datos PostgreSQL en Azure
DATABASE_URL=postgresql+psycopg2://<usuario>:<contraseÃ±a>@<host>:5432/<database>
```

Este valor se usa tanto en Airflow como en la aplicaciÃ³n Streamlit.

---

## ğŸ§© DAG principal (`earthquake_etl`)

- Extrae los datos de sismos en tiempo real desde **USGS Earthquake API**
- Realiza transformaciones de limpieza y filtrado (por ejemplo, magnitud mÃ­nima)
- Carga los datos en la base **PostgreSQL (Azure)**
- Corre automÃ¡ticamente **cada 1 hora** mediante Apache Airflow

---

## ğŸ“Š VisualizaciÃ³n con Streamlit

Para ver los sismos en una app web interactiva:

```bash
cd streamlit_app
streamlit run visualizar_streamlit.py
```

Asegurate de tener correctamente seteado el archivo `.env` con la conexiÃ³n a PostgreSQL.

---

## ğŸ” Seguridad

- Nunca se sube el archivo `.env` al repositorio.
- Las credenciales se gestionan a travÃ©s de variables de entorno.
- Se provee un archivo `.env.example` con la estructura necesaria.

---

## ğŸ”§ PersonalizaciÃ³n

PodÃ©s modificar:

- La magnitud mÃ­nima filtrada en la transformaciÃ³n
- El intervalo de ejecuciÃ³n del DAG (actualmente cada 1 hora)
- El dashboard en Streamlit para mejorar visualizaciones

---

## ğŸ§ª Pruebas (opcional)

PodÃ©s agregar pruebas unitarias en una carpeta `/tests`, por ejemplo:

- VerificaciÃ³n de conexiÃ³n a PostgreSQL
- ValidaciÃ³n del esquema del DataFrame
- Tests de la lÃ³gica de transformaciÃ³n

---

## ğŸ“„ Licencia

MIT Â© Fernando Pedernera

---

## ğŸ¤ Contacto

ğŸ“§ fer.pedernera@gmail.com  
ğŸ”— [LinkedIn](https://www.linkedin.com)
